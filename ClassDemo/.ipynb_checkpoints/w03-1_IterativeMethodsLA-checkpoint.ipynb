{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Systems and Iterative Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import time\n",
    "\n",
    "\n",
    "np.set_printoptions( suppress=True, formatter={'float': '{: 0.2f}'.format}, linewidth=180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most frequently-encountered problems in astrophysics is determining the solution to Poisson's equation\n",
    "$$ \\nabla^2 \\phi = \\rho $$\n",
    "As an excuse to do some linear algebra, let's explore a simple method to attack this PDE on a finite domain in 2D.\n",
    "\n",
    "Define a 2D, $N\\times N$ uniform grid as the set of points $\\left\\{(x_i,y_j)\\right\\}$ with $x_i = x_0 + i h$ and $y_i = y_0 + j h$, and $i,j = 0,\\dots,N-1$.  \n",
    "We will be computing the solution at the grid points, $\\phi(x_i,y_j)$. To make the notation more compact, we will write $\\phi_{i,j} = \\phi(x_i,y_j)$.\n",
    "\n",
    "A simple *finite difference* approximation to $\\partial \\phi/\\partial x$ evaluated at $(x_i,y_j)$ is \n",
    "$$ \\left.\\frac{\\partial \\phi}{\\partial x}\\right|_{(x,y)=(x_i,y_j)} = \\frac{\\phi_{i+1,j}-\\phi_{i,j}}{h}$$\n",
    "To the same order of approximation, we cana write the $x$-derivative at $(x_i,y_j)$ as\n",
    "$$ \\left.\\frac{\\partial \\phi}{\\partial x}\\right|_{(x,y)=(x_i,y_j)} = \\frac{\\phi_{i,j}-\\phi_{i-1,j}}{h}$$\n",
    "\n",
    "We can approximate the second derivative as the \"derivative of a derivative\" using finite-differences as\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\left.\\frac{\\partial^2 \\phi}{\\partial x^2}\\right|_{(x,y)=(x_i,y_j)} &= \\frac{ \\frac{\\phi_{i+1,j}-\\phi_{i,j}}{h} - \\frac{\\phi_{i,j}-\\phi_{i-1,j}}{h} }{h} \\\\\n",
    "&= \\frac{\\phi_{i+1,j} - 2\\phi_{i,j} + \\phi_{i-1,j}}{h^2}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "Using this approximation, we can write a finite-difference representation of Poisson's equation on our grid as\n",
    "$$ \\frac{\\phi_{i+1,j} - 2\\phi_{i,j} + \\phi_{i-1,j}}{h^2} + \\frac{\\phi_{i,j+1} - 2\\phi_{i,j} + \\phi_{i,j-1}}{h^2} = \\rho_{i,j} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a linear system with $N^2$ unknowns, the $\\phi_{i,j}$.  \n",
    "To simplify array indexing, \n",
    "map the grid index pairs $(i,j)$, $i = 0,...,N-1$ and $j=0,\\dots,N-1$ into the one-dimensional\n",
    "ordering $k=(N_y-1) i + j$, so that $k=0,\\dots,N^2-1$.\n",
    "\n",
    "We can now write the finite-difference equation above, away from the boundaries, as\n",
    "$$  \\phi_{i-1} + \\phi_{i+1} + \\phi_{i-N-1} + \\phi_{i+N+1} - 4\\phi_i= h^2 \\rho_i $$\n",
    "On the boundaries, some of these terms will either be specified (Dirichlet) or replaced by other terms (periodic or Neumann).\n",
    "\n",
    "This can be written as a linear system, $\\mathsf{A} \\boldsymbol{x} = \\boldsymbol{b}$. Notice that the matrix $\\mathsf{A}$ is mostly zeros; this is known as a _sparse matrix_. For many boundary conditions, $\\mathsf{A}$ will be band-diagonal. In this case, the diagonal and the first upper- and lower-diagonal will be non-zero, and then another non-zero diagonal $N-1$ away.\n",
    "\n",
    "In fact, this matrix is _block tridiagonal_, which makes solving it even easer, but we will ignore this for now.\n",
    "\n",
    "We can get a picture of this structure, with the diagonal elements in purple and the off-diagonal elements in yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdFill(N):\n",
    "    \"\"\"\n",
    "    Return 2D Laplacian finite-differece matrix\n",
    "    \"\"\"\n",
    "    N2 = N*N\n",
    "    A = -4*np.eye(N2,N2) + np.eye(N2,N2,k=-1) + np.eye(N2,N2,k=+1) \\\n",
    "        + np.eye(N2,N2,k=-N) + np.eye(N2,N2,k=N)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f3c084d141485994772cc69e808b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 5\n",
    "A = fdFill(N)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(A, extent=(0,N**2,N**2,0))\n",
    "ax.grid(which='major', color='b')\n",
    "plt.colorbar(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "Before we go any further, we need a test problem!\n",
    "\n",
    "We'll use the so-called \"method of manufactured solutions\" wherein one designs a solution, and then\n",
    "applies the differential operator to it to find the corresponding source terms. This is a powerful technique to develop test problems for PDE solvers.\n",
    "\n",
    "A nice answer for a 2D elliptic solver is a gaussian-like, centrally-peaked solution in the solution domain $\\Omega$, but one which obeys the homogeneous Dirichlet boundaries: $\\phi(\\boldsymbol{x}) = 0, \\forall \\boldsymbol{x}\\in\\partial\\Omega$\n",
    "\n",
    "Such a function is\n",
    "$$ \\phi(x,y,a) = 2^{4a} x^a (x-1)^a y^a (y-1)^a $$\n",
    "on the unit square.\n",
    "\n",
    "To get this as a solution to $\\nabla^2 \\phi = \\rho$, we can apply the operator $\\nabla^2$ to our\n",
    "solution $\\phi$ to obtain the (slightly ugly) source term (the right-hand side of our Poisson equation)\n",
    "$$ \\rho(x,y,a) = 16^a a (x(x-1))^a (y(y-1))^a \\left(\n",
    "\\frac{a(1-2x)^2 - 2(x-1)x - 1}{x^2(x-1)^2} + \n",
    "\\frac{a(1-2y)^2 - 2(y-1)y - 1}{y^2(y-1)^2} \\right) $$\n",
    "\n",
    "The solution $\\phi$ looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bc3d846c474b189e23fb5ad983299e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ans(x,y,a):\n",
    "    \"\"\"\n",
    "    Analytic solution to our manufactured problem\n",
    "    \"\"\"\n",
    "    return 2**(4*a) * (x * (1-x))**a * (y * (1-y))**a\n",
    "    \n",
    "def fac(x,y,a):\n",
    "    return (16**a)* a* ((-(-1 + x)* x)**a) * ((-(-1 + y)*y)**a)\n",
    "\n",
    "def term(x,a):\n",
    "    \n",
    "    # take care of l'Hopital's rule on the boudaries...\n",
    "    indx = (x!=0) & (x!=1)\n",
    "    result = np.zeros_like(x, dtype=np.float64)\n",
    "    result[indx] = (-1 + a*(1 - 2*x[indx])**2 - 2*(-1 + x[indx])*x[indx])/((-1 + x[indx])**2*x[indx]**2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def rhs(x,y,a):\n",
    "    \"\"\"\n",
    "    source term to give result in ans() from 2D Poisson's equation\n",
    "    \"\"\"\n",
    "    return fac(x,y,a) * (term(x,a)+term(y,a))\n",
    "\n",
    "def getRHS(N, a):\n",
    "    xx = np.arange(N)/N\n",
    "    XX,YY = np.meshgrid(xx,xx)\n",
    "    h = xx[1]-xx[0]\n",
    "    return h, rhs(XX,YY,a) * h**2\n",
    "\n",
    "def getAns(N, a):\n",
    "    xx = np.arange(N)/N\n",
    "    XX,YY = np.meshgrid(xx,xx)\n",
    "    return xx, XX, YY, ans(XX,YY,a)\n",
    "\n",
    "N = 64\n",
    "a = 10\n",
    "h, b = getRHS(N, a)\n",
    "xx, XX, YY, phi = getAns(N,a)\n",
    "\n",
    "fig, ax = plt.subplots(2,2)\n",
    "ax[0,0].plot(xx,phi[:,N//2])\n",
    "ax[0,0].set_ylabel(r\"$\\phi$\")\n",
    "ax[0,0].set_xlabel(r\"$x$\")\n",
    "\n",
    "ax[1,0].plot(xx,-b[:,N//2])\n",
    "ax[1,0].set_ylabel(r\"$-\\rho$\")\n",
    "ax[1,0].set_xlabel(r\"$x$\")\n",
    "\n",
    "cphi = ax[0,1].imshow(phi)\n",
    "ax[0,1].set_xlabel(r\"$x$\")\n",
    "ax[0,1].set_ylabel(r\"$y$\")\n",
    "fig.colorbar(cphi,ax=ax[0,1])\n",
    "\n",
    "crho=ax[1,1].imshow(-b);\n",
    "ax[1,1].set_xlabel(r\"$x$\")\n",
    "ax[1,1].set_ylabel(r\"$y$\")\n",
    "fig.colorbar(crho, ax=ax[1,1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can solve the discrete problem using a linear system solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ba50e5f6354ed0836b04cf14360afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|error| = 0.002420158228261693\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "a = 10\n",
    "A = fdFill(N)\n",
    "h,b = getRHS(N,a)\n",
    "\n",
    "# use the solve function to use LU decomposition for a solution\n",
    "phi = linalg.solve(A,b.flatten())\n",
    "phi = np.reshape(phi, (N,N) )\n",
    "\n",
    "fig,ax = plt.subplots(2,2)\n",
    "ax[0,0].plot(xx, phi[:,N//2])\n",
    "ax[0,0].plot(xx, ans(xx,xx[N//2],a),'r.' )\n",
    "ax[0,0].set_ylabel(r'$\\phi(x,N/2)$')\n",
    "ax[0,0].set_xlabel(r\"$x$\")\n",
    "\n",
    "im = ax[0,1].imshow(phi)\n",
    "ax[0,1].set_xlabel(r\"$x$\")\n",
    "ax[0,1].set_ylabel(r\"$y$\")\n",
    "fig.colorbar(im, ax=ax[0,1])\n",
    "\n",
    "resid = phi - ans(XX,YY,a)\n",
    "ax[1,0].plot(xx, resid[:,N//2])\n",
    "ax[1,0].set_xlabel(r\"$x$\")\n",
    "ax[1,0].set_ylabel(r\"$residual(x,N/2)$\")\n",
    "\n",
    "imp = ax[1,1].imshow(resid)\n",
    "ax[1,1].set_xlabel(r\"$x$\")\n",
    "ax[1,1].set_ylabel(r\"$y$\")\n",
    "fig.colorbar(imp, ax=ax[1,1])\n",
    "\n",
    "error = np.amax(np.abs(phi.flatten() - ans(XX,YY,a).flatten()))\n",
    "print(f\"|error| = {error}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, one would never store the full set of elements of $\\mathsf{A}$ since virtually all of them are zero.\n",
    "Indeed, for typical grids we would never be able to afford to do so. Even a 400x400 2D grid would involve storing $400^4$ numbers -- almost 26 billion. The total number of non-zeros is less than $5N$ instead of $N^2$, so we should seek a more efficient scheme.\n",
    "\n",
    "A linear system in which a *useful* fraction of the matrix elements are zero in known as a *sparse linear system*. There are many schemes for solving sparse systems, especially those with a lot of structure in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some very structured sparse matrices arise often enough that they have names and often special, more-efficient algorithms for solving their associated linear systems. One such\n",
    "structure is *band-diagonal*. For example the matrix arising from the 1D version of our test problem has $-2$ on the main diagonal and $1$ on the sub- and super diagonals; it has a band width of 3.\n",
    "Our 2D version is also band-diagonal, but with a band width of $2N+1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00  1.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00  1.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  1.00  0.00  0.00  1.00 -4.00]]\n"
     ]
    }
   ],
   "source": [
    "samp = fdFill(4)\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These structured matrices are often stored in some more compact form to avoid storing at least many of the zeros. For example, a standard form used for band-diagonal matrices is\n",
    "to build a matrix whose rows are the bands. For our 2D problem, such a matrix would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00  0.00  0.00  0.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00]\n",
      " [-4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00 -4.00]\n",
      " [ 1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00]\n",
      " [ 1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00  1.00]]\n"
     ]
    }
   ],
   "source": [
    "def fdFillBanded(N):\n",
    "    # band-width is 2N+1, so matrix has 2N+1 rows and N^2 columns\n",
    "    A = np.zeros((2*N+1, N*N))\n",
    "    # top band is all ones;, but the first $N$ columns aren't there\n",
    "    A[0,N:] = 1\n",
    "    # next band is just above the diagonal, so row N-1\n",
    "    A[N-1,:] = 1\n",
    "    # next band is diagonal\n",
    "    A[N,:] = -4\n",
    "    # next band is just below the diagonal, so row N+1\n",
    "    A[N+1,:] = 1\n",
    "    # last band is row 2N\n",
    "    A[2*N,:] = 1\n",
    "    \n",
    "    return A\n",
    "\n",
    "samp = fdFillBanded(4)\n",
    "print(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using the band-diagonal solver, timing this solve and the full matrix solve we used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Aband: 528384   2N^3: 524288\n",
      "time for band solve: 0.012199987948406488\n",
      "\n",
      "size of Afull: 16777216   N^4: 16777216\n",
      "time for full solve: 0.9737768689519726\n",
      "\n",
      "we got the same answer: True\n",
      "\n",
      "band solve takes 0.01252852510404845 of the time, and 0.031494140625 of the storage\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "a = 10\n",
    "h, b = getRHS(N,a)\n",
    "Aband = fdFillBanded(N)\n",
    "print(f\"size of Aband: {Aband.size}   2N^3: {2*N**3}\")\n",
    "# do band solve\n",
    "t0 = time.perf_counter()\n",
    "u = linalg.solve_banded((N,N), Aband, b.flatten())\n",
    "t_band = time.perf_counter()-t0\n",
    "print(f\"time for band solve: {t_band}\")\n",
    "print()\n",
    "\n",
    "# do full solve for timing\n",
    "t0 = time.perf_counter()\n",
    "Afull = fdFill(N)\n",
    "print(f\"size of Afull: {Afull.size}   N^4: {N**4}\")\n",
    "phi = linalg.solve(Afull, b.flatten())\n",
    "t_full = time.perf_counter()-t0\n",
    "print(f\"time for full solve: {t_full}\")\n",
    "print()\n",
    "# make sure we get same answer!\n",
    "print(f\"we got the same answer: {np.allclose(u, phi, rtol=1e-13, atol=1e-13)}\")\n",
    "print()\n",
    "print(f\"band solve takes {t_band/t_full} of the time, and {Aband.size/Afull.size} of the storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we save a factor of $N/2$ in storage and a factor of 100 in time for the $N=64$ problem.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another commonly-encountered structure is *block tridiagonal*.\n",
    "$$  \\begin{bmatrix}\n",
    "B_0 & C_0&  &  &  & \\\\\n",
    "A_1 & B_1& C_1&  &  & \\\\\n",
    "  & \\ddots & \\ddots & \\ddots &  & \\\\\n",
    "  &  & A_{M-2}& B_{M-2}& C_{M-2}&  \\\\\n",
    "  &  &  & A_{M-1}& B_{M-1}\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "where the block matrices $A_i, B_i$, and $C_i$ are $N\\times N$ and the system has $3M$ blocks. The storage is thus $3 M N^3$ rather than $M^2 N^2$.\n",
    "In the case where the  blocks $A_i, B_i$, and $C_i$ are independent of $i$, the storage is then $3N^2$.\n",
    "\n",
    "We can express our exmaple linear system as a block-tridiagonal one in which the diagonal blocks are\n",
    "$$ \\mathsf{B} = \\begin{bmatrix}\n",
    "-4 & 1 &  &  &  & \\\\\n",
    " 1 &-4 & 1&  &  & \\\\\n",
    "   & \\ddots &\\ddots& \\ddots&  & \\\\\n",
    "   &   & 1&-4& 1&  \\\\\n",
    "   &   &  & 1& -4 \n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "and the upper- and lower-diagonal blocks are\n",
    "$$ \\mathsf{A} = \\begin{bmatrix}\n",
    " 1 &  &  &  & 1 & \\\\\n",
    "   & 1&  &  &  & \\\\\n",
    "   &  &\\ddots& &  & \\\\\n",
    "   &   &  & 1&  &  \\\\\n",
    "   &   &  &  & 1\n",
    "   \\end{bmatrix}, \\quad\\quad\n",
    "   \\mathsf{C} = \\begin{bmatrix}\n",
    " 1 &  &  &  &  & \\\\\n",
    "   & 1&  &  &  & \\\\\n",
    "   &  &\\ddots& &  & \\\\\n",
    "   &   &  & 1&  &  \\\\\n",
    "  1 &   &  &  & 1\n",
    "   \\end{bmatrix}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can form our block-tridiagonal system matrices as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "Ablock = np.eye(N,N)\n",
    "Ablock[0,-1] = 1\n",
    "\n",
    "Bblock = -4*np.eye(N,N) + np.eye(N,N,k=1) + np.eye(N,N,k=-1)\n",
    "\n",
    "Cblock = np.eye(N,N)\n",
    "Cblock[-1,0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a general block-tridiagonal solver which does not assume that all of the $A_i$, $B_i$, and $C_i$ are constant with $i$, we make three matrix-valued vectors from our blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 64\n",
    "At = np.tile(Ablock, (M,1)).reshape(M,N,N)\n",
    "Bt = np.tile(Bblock, (M,1)).reshape(M,N,N)\n",
    "Ct = np.tile(Cblock, (M,1)).reshape(M,N,N)\n",
    "h, b = getRHS(N,a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to check, we will fill a full matrix using these blocks and compare it with the corresponding full-storage matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# make full-storage block tridiagonal matrix from At, Bt, and Ct\n",
    "S = M*N\n",
    "samp = np.zeros((S,S))\n",
    "for i in range(M):\n",
    "    \n",
    "    # superdiagonal blocks\n",
    "    if i<M-1:\n",
    "        samp[i*N:(i+1)*N, (i+1)*N:(i+2)*N] = Ct[i,:,:]\n",
    "\n",
    "    # diagonal blocks\n",
    "    samp[    i*N:(i+1)*N,     i*N:(i+1)*N] = Bt[i,:,:]\n",
    "\n",
    "    # subdiagonal blocks\n",
    "    if i>0:\n",
    "        samp[i*N:(i+1)*N, (i-1)*N:    i*N] = At[i,:,:]\n",
    "\n",
    "Afull = fdFill(N)\n",
    "print(np.allclose(A, samp, rtol=1e-13, atol=1e-13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the algorithm for solving a block-tridiagonal system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockTridiagonalSolve(A, B, C, rhs):\n",
    "    M, N, N = B.shape\n",
    "    G = np.zeros((M,N,N))\n",
    "    u = np.zeros((M,N))\n",
    "    Binv = np.zeros((N,N))\n",
    "    \n",
    "    # forward triangularization\n",
    "    Binv = linalg.inv(B[0]) \n",
    "    u[0,:] = Binv @ rhs[0,:]\n",
    "\n",
    "    for block in range(1,M):\n",
    "        G[block,:,:] = Binv @ C[block-1]\n",
    "        Binv = linalg.inv(B[block]-A[block]@G[block])\n",
    "        u[block,:] = Binv @ (rhs[block]-A[block]@u[block-1])\n",
    "\n",
    "    # back substitution\n",
    "    for block in range(M-2,-1,-1):\n",
    "        u[block,:] -= G[block+1] @ u[block+1]\n",
    "          \n",
    "    return u.reshape(N,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block TD solve time: 0.024319299031049013\n",
      "\n",
      "    full solve time: 0.7524965520133264\n",
      "\n",
      "we got the same answer: True\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "u = blockTridiagonalSolve(At,Bt,Ct,b)\n",
    "print(f\"block TD solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "up = linalg.solve(A, b.flatten()).reshape(N,N)\n",
    "print(f\"    full solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "print(f\"we got the same answer: {np.allclose(u,up, rtol=1e-13, atol=1e-13)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tridiagonal solve took longer than the band solve since the algorithm given interprets each block as a full matrix.\n",
    "In a \"production\" code, we might have taken the structure of the individual blocks into account when performing the $M$ $N\\times N$ inversions.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often one has a linear system with enough sparsity to matter, but with no simple structure. There are several ways to store a general sparse matrix; one is by specifying the row and column of each non-zero matrix element.\n",
    "For our problem, we can write a function to put our matrix into sparse format and then create a `scipy.sparse.csc_matrix` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdFillSparse(N,a):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    elem = []\n",
    "\n",
    "    # loop over rows\n",
    "    for i in range(N*N):\n",
    "        # diagonal: columm is i\n",
    "        rows.append(i)\n",
    "        cols.append(i)\n",
    "        elem.append(-4.0)\n",
    "\n",
    "        # sub-diagonals: columns less than i\n",
    "        if i>0:\n",
    "            rows.append(i)\n",
    "            cols.append(i-1)\n",
    "            elem.append(1.0)\n",
    "        if i>=N:\n",
    "            rows.append(i)\n",
    "            cols.append(i-N)\n",
    "            elem.append(1.0)\n",
    "            \n",
    "        # super-diagonals: columns greater than i\n",
    "        if i<N**2-1:\n",
    "            rows.append(i)\n",
    "            cols.append(i+1)\n",
    "            elem.append(1.0)\n",
    "        if i<N**2-N:\n",
    "            rows.append(i)\n",
    "            cols.append(i+N)\n",
    "            elem.append(1.0)\n",
    "\n",
    "    return sparse.csc_matrix((np.array(elem, dtype=float), (np.array(rows, dtype=int), np.array(cols, dtype=int))), shape=(N*N, N*N) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out; the csc_matrix object has a toarray() function which is conventient to use for checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00,  1.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00,  1.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  0.00,  1.00,  0.00,  0.00,  1.00, -4.00]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "Acsc = fdFillSparse(N,a)\n",
    "Acsc.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try using it to solve our problem; note how little storage is required to store our matrix. It would appear that this form of sparse matrix\n",
    "storage gives about the same solution speed as for the banded matrix above, but in this case the storage scheme does not depend upon knowning the\n",
    "sparsity pattern in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of csc matrix object: 20350   20350\n",
      "\n",
      "spsolve solve time: 0.014652960002422333\n",
      "\n",
      "   full solve time: 0.8685435259831138\n",
      "\n",
      "we got the same answer: True\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "a = 10\n",
    "h, b = getRHS(N,a)\n",
    "Acsc = fdFillSparse(N,a)\n",
    "print(f\"Size of csc matrix object: {Acsc.size}   {N**2 + (N**2-1)*2 + (N**2-N)*2}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "u = splinalg.spsolve(Acsc, b.flatten())\n",
    "print(f\"spsolve solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "up = linalg.solve(A, b.flatten())\n",
    "print(f\"   full solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "\n",
    "print(f\"we got the same answer: {np.allclose(u,up, rtol=1e-13, atol=1e-13)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Solvers\n",
    "\n",
    "All of the various linear system solvers we have used so far are examples of *direct* solvers. We now turn to *iterative* solvers, solvers which iterate in various ways\n",
    "to minimize the *residual* $\\mathsf{A} \\mathbf{x} - \\mathbf{b}$.\n",
    "\n",
    "One class of iterative solver splits the matrix $A$ into\n",
    "$$ A = M - N $$\n",
    "If $M$ is easily invertable, then we can write an iterative scheme as\n",
    "$$ M x_{i+1} = N x_i + b $$\n",
    "If the exact solution is $x_*$, then the error is\n",
    "$$e_k = x_k-x_*$$\n",
    "and we can write the iteration as\n",
    "$$ e_{k+1} = C e_k$$\n",
    "where the *iteration matrix* is\n",
    "$$ C = I - M^{-1}A = M^{-1}N $$\n",
    "If the spectral radius (the maximum magnitude of its eigenvalues) $\\rho(C) < 1$, the iteration will converge since in this case\n",
    "$$\\lim_{i\\rightarrow\\infty} C^k = 0$$.\n",
    "\n",
    "These iterative schemes are known as *relaxation methods* as the solution is seen to \"relax\" to the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common partitioning of $A$ is into its (strictly) lower-diagonal, diagonal, and upper-diagonal parts\n",
    "$$ A = L + D + U $$\n",
    "There are then a number of choices for which combination of $L, D$, and $U$ to invert and which to iterate.\n",
    "\n",
    "The simplest method is known as *Jacobi iteration*, with $M=D$ and $N=L+U$\n",
    "$$ D x_{i+1} = b - (L+U) x_i $$\n",
    "Since $D$ is trivial to invert, we have\n",
    "$$ x_{i+1} = D^{-1} \\left(b - (L+U)x_i\\right) $$\n",
    "(The problem with Jacobi iteration is that, for matrices which derive from finite differences as in our test problem, the number of iterations required to converge is proportional to the number of mesh points $N^2$.)\n",
    "\n",
    "If we choose $M=D+L$ we have *Gauss-Seidel iteration*:\n",
    "$$ (D+L) x_{i+1} = b - U x_i $$\n",
    "This is still quite easy to solve since the system is triangular; we only need to do back-substitution. (Of course, we *never* invert $D+L$, we\n",
    "solve the linear system...).\n",
    "\n",
    "There is a whole theory of how to accelerate the convergence of these iterations by over-correcting; for example, choosing\n",
    "$ M = \\frac{1}{\\omega} D + L $ is known as *successive over-relaxation* (SOR). Under similar assumption, SOR converges in something like $N$ iterations, a significant improvement over Jacobi iteration.\n",
    "\n",
    "These relaxation methods used to be state of the art for solving PDE boundary-value problems, and can still be useful if you need something quick and dirty.\n",
    "They have largely been replaced by multigrid solvers and by Krylov subspace solvers, which we consider next (we will explore multigrid later in the semester)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The simplest form of Krylov subspace methods assumes that $\\mathsf{A}$ is symmetric and positive-definite, and mimimizes the scalar function\n",
    "$$ f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T\\mathsf{A}\\mathbf{x} - \\mathbf{x}^T\\mathbf{b} $$\n",
    "for which the solution is the only minimum since $\\nabla f(\\mathbf{x}) = \\mathsf{A} \\mathbf{x} - \\mathbf{b}$ and $\\nabla^2 f(\\mathbf{x}) = \\mathsf{A}$.\n",
    "\n",
    "The algorithm takes an initial guess at a solution $\\mathbf{x}_0$ and then generates a sequence of directions $\\mathbf{p}_k$, and improved solutions $\\mathbf{x}_k$,\n",
    "such that at each step $f(\\mathbf{x}_k + \\alpha_k \\mathbf{p}_k)$ is minimized for some $\\alpha_k$ along $\\mathbf{p}_k$ and that $\\mathbf{p}_k$ is orthonormal to all previous directions.\n",
    "That is, at each iteration the set $\\left\\{\\mathbf{p}_0,\\dots,\\mathbf{p}_k\\right\\}$ spans the *Krylov subspace* formed by the images of $\\mathbf{b}$ under powers of $\\mathsf{A}$, $\\mathrm{span}\\left\\{\\mathbf{b}, \\mathsf{A}\\mathbf{b}, \\mathsf{A}^2\\mathbf{b}, \\dots, \\mathsf{A}^{k-1}\\mathbf{b}\\right\\}$.\n",
    "\n",
    "For an $N\\times N$ matrix $\\mathsf{A}$, after $N$ iterations the set $\\left\\{\\mathbf{p}_k\\right\\}$ will form an orthonormal basis for the entire vector space and $\\mathbf{x}_{N-1}$ will be the solution. (see the Wikipedia article on \"Congugate Gradient method\" for a derivation).\n",
    "\n",
    "Well, almost. Roundoff error will prevent this from happening, so instead we iterate the process until\n",
    "the error, which can be defined in a variety of ways depending upon your application, is met.\n",
    "\n",
    "This algorithm can be generalized and made more robust, leading to the Biconjugate Gradient, BiCGSTAB (BiConjugate Gradiant STABilized), GMRES (General Minimum RESidual), and other methods. The efficiency of each of these methods depends in some detail on the actual system being solved; experiment usually guides adoption of one of them.\n",
    "\n",
    "Let's try out biconjugate gradient (even though our $A$ is symmetric!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "One of the features of these methods is that they employ the matrix $\\mathsf{A}$ only when multiplying it (or its transpose) with a vector. Thus, the user interface frequentlytakes a function which performs these multiplications. How you store, or even *if* you store, the matrix is up to you. The `scipy` routines will take either a sparse matrix in some form or a linear operator which does this multiplication. We will provide the latter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matVec(v):\n",
    "    # multiply the vector v by our N^2 by N^2 matrix A\n",
    "    r = np.zeros_like(v);\n",
    "    N = int(np.sqrt(v.shape[0]))\n",
    "    if N*N != v.shape[0]:\n",
    "        raise ValueError(\"bad dimension in matVec\")\n",
    "\n",
    "    for row in range(N*N):\n",
    "        #diagonal\n",
    "        r[row] = -4*v[row]\n",
    "        # sub-diagonals\n",
    "        if row>0:\n",
    "            r[row] += v[row-1]\n",
    "        if row>=N:\n",
    "            r[row] += v[row-N]\n",
    "        # super-diagonals\n",
    "        if row<N**2-1:\n",
    "            r[row] += v[row+1]\n",
    "        if row<N**2-N:\n",
    "            r[row] += v[row+N]\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our LinearOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 64\n",
    "Aop = splinalg.LinearOperator((N**2,N**2), matvec=matVec, rmatvec=matVec) # rmatvec is matVec since A is real and symmetric\n",
    "\n",
    "v = np.random.random(N**2)\n",
    "r1 = Aop.matvec(v)\n",
    "r2 = A @ v\n",
    "np.allclose(r1,r2, rtol=1e-13, atol=1e-13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "and now solve our system yet again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: 0\n",
      "spsolve solve time: 2.9563293689861894\n",
      "\n",
      "   full solve time: 0.7029557150090113\n",
      "\n",
      "we got the same answer: True\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "a = 10\n",
    "h, b = getRHS(N,a)\n",
    "b = b.flatten()\n",
    "eps = 1e-5\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "u, info = splinalg.bicg(Aop, b, x0=np.zeros(N**2), tol=eps)\n",
    "print(f\"info: {info}\")\n",
    "print(f\"spsolve solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "up = linalg.solve(A, b.flatten())\n",
    "print(f\"   full solve time: {time.perf_counter()-t0}\")\n",
    "print()\n",
    "\n",
    "print(f\"we got the same answer: {np.allclose(u,up, rtol=eps, atol=eps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "If the condition number of a linear system is large, we may be able to reduce it by *preconditioning*.\n",
    "\n",
    "Instead of solving the system $Ax - b = 0$, we consider solving\n",
    "$$ P^{-1}(Ax - b) = 0 $$\n",
    "or\n",
    "$$ (P^{-1}A) x = -P^{-1} b$$\n",
    "If the condition number of $P^{-1}A$ is significantly less than that of $A$, solving the preconditioned system  will improve the accuracy of a direct solve and reduce the number of iterations in an iterative solve. The question is how to choose $P$.\n",
    "\n",
    "One common way is to return to the discussion of relaxation methods, above, and consider a matrix splitting\n",
    "$ A = M - N$. For our example problem, we might consider using the tridiagonal part of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27, -0.07, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.07, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01, -0.00],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02, -0.01],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.08, -0.02],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.08, -0.29, -0.07],\n",
       "       [-0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.00, -0.01, -0.02, -0.07, -0.27]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "A = fdFill(N)\n",
    "P = np.diag(np.diag(A,k=-1),k=-1) + np.diag(np.diag(A)) + np.diag(np.diag(A,k=1),k=1)\n",
    "Pinv = linalg.inv(P)\n",
    "Pinv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is a banded matrix of width 7. Try out the preconditioning, looking at the condition number of $\\mathsf{A}$ and of the preconditioned $\\mathsf{A=P}^{-1}\\mathsf{A}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond(A) = 3418.2633190355964\n",
      "cond(Pinv@A) = 1708.1218805585654\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "A = fdFill(N)\n",
    "P = np.diag(np.diag(A,k=-1),k=-1) + np.diag(np.diag(A)) + np.diag(np.diag(A,k=1),k=1)\n",
    "Pinv = linalg.inv(P)\n",
    "\n",
    "print(f\"cond(A) = {np.linalg.cond(A)}\")\n",
    "print(f\"cond(Pinv@A) = {np.linalg.cond(Pinv @ A)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We get almost as much effect if we take just the tridiagonal part of Pinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond(A) = 3418.2633190355964\n",
      "cond(Pinv@A) = 1764.982493537916\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "A = fdFill(N)\n",
    "P = np.diag(np.diag(A,k=-1),k=-1) + np.diag(np.diag(A)) + np.diag(np.diag(A,k=1),k=1)\n",
    "Pinv = linalg.inv(P)\n",
    "PinvT = np.diag(np.diag(Pinv,k=-1),k=-1) + np.diag(np.diag(Pinv)) + np.diag(np.diag(Pinv,k=1),k=1)\n",
    "\n",
    "print(f\"cond(A) = {np.linalg.cond(A)}\")\n",
    "print(f\"cond(Pinv@A) = {np.linalg.cond(PinvT @ A)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give the preconditioner to bicg via an optional argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: 0\n",
      "spsolve solve time: 3.2368049870128743\n",
      "   full solve time: 0.7340224310173653\n",
      "we got the same answer: True\n"
     ]
    }
   ],
   "source": [
    "N = 64\n",
    "a = 10\n",
    "h, b = getRHS(N,a)\n",
    "b = b.flatten()\n",
    "eps = 1e-5\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "u, info = splinalg.bicg(Aop, b, x0=np.zeros(N**2), tol=eps, M=PinvT)\n",
    "print(f\"info: {info}\")\n",
    "print(f\"spsolve solve time: {time.perf_counter()-t0}\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "up = linalg.solve(A, b)\n",
    "print(f\"   full solve time: {time.perf_counter()-t0}\")\n",
    "\n",
    "print(f\"we got the same answer: {np.allclose(u,up, rtol=eps, atol=eps)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterative time is longer than the direct solve! This is not surprising. First, the system is not very large, and second, we are giving bicg the tridiagonal preconditioner as a full matrix; the routine is doing quite a few unnecesary multiplications by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
